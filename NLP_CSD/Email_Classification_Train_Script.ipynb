{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "#df = pd.read_csv('Consumer_Complaints.csv')\n",
    "df = pd.read_csv('14000_set.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[pd.notnull(df['Consumer complaint narrative'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Product', 'Consumer complaint narrative']\n",
    "df = df[col]\n",
    "df.columns = ['Product', 'Consumer_complaint_narrative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Product', 'Consumer_complaint_narrative']\n",
    "ind_drop = df[df['Product'].apply(lambda x: x.startswith(('BMC issue' , 'Wallboard issue' , 'BMC issue' , 'Citrix issue' , 'Greenplum Issues' , 'IPCM Error' , 'IPCM error' , 'Missing Folder in MBNL' , 'Monolith panel error' , 'Network Protect Issues' , 'Other Issues' , 'Pegaplan error' , 'RAN request form' , 'Talend Issues' )))].index\n",
    "df.drop(ind_drop, inplace=True)\n",
    "df.loc[df['Product'].apply(lambda x: x.startswith(('Account Reset','Log in Issues' )))] = 'Account Locked'\n",
    "df.loc[df['Product'].apply(lambda x: x.startswith(('Tool set access request','tool set access request' )))] = 'New Account'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Consumer_complaint_narrative</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Account Locked</td>\n",
       "      <td>Hi,       Kindly unlock the mentioned IP...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Account Locked</td>\n",
       "      <td>Good Morning,     Please see the update fro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Account Locked</td>\n",
       "      <td>Hi      Can you please assist with this?   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Account Locked</td>\n",
       "      <td>Hi team      I can??t login to  SIAE  NMS ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Account Locked</td>\n",
       "      <td>Hi Team,        Can you please reset my U20...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Product                       Consumer_complaint_narrative  \\\n",
       "0  Account Locked        Hi,       Kindly unlock the mentioned IP...   \n",
       "1  Account Locked     Good Morning,     Please see the update fro...   \n",
       "2  Account Locked     Hi      Can you please assist with this?   ...   \n",
       "3  Account Locked     Hi team      I can??t login to  SIAE  NMS ...   \n",
       "4  Account Locked     Hi Team,        Can you please reset my U20...   \n",
       "\n",
       "   category_id  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category_id'] = df['Product'].factorize()[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\emueana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Consumer_complaint_narrative</th>\n",
       "      <th>category_id</th>\n",
       "      <th>New_Consumer_complaint_narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Account Locked</td>\n",
       "      <td>Hi,       Kindly unlock the mentioned IP...</td>\n",
       "      <td>0</td>\n",
       "      <td>hi kindly unlock the mentioned ipcm account us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Account Locked</td>\n",
       "      <td>Good Morning,     Please see the update fro...</td>\n",
       "      <td>0</td>\n",
       "      <td>good morning plese see the updte from the supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Account Locked</td>\n",
       "      <td>Hi      Can you please assist with this?   ...</td>\n",
       "      <td>0</td>\n",
       "      <td>hi can you please assist with this am unable t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Account Locked</td>\n",
       "      <td>Hi team      I can??t login to  SIAE  NMS ...</td>\n",
       "      <td>0</td>\n",
       "      <td>hi eam can login o sae nm maser wed nm applica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Account Locked</td>\n",
       "      <td>Hi Team,        Can you please reset my U20...</td>\n",
       "      <td>0</td>\n",
       "      <td>hi team can you please reset my password a am ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Product                       Consumer_complaint_narrative  \\\n",
       "0  Account Locked        Hi,       Kindly unlock the mentioned IP...   \n",
       "1  Account Locked     Good Morning,     Please see the update fro...   \n",
       "2  Account Locked     Hi      Can you please assist with this?   ...   \n",
       "3  Account Locked     Hi team      I can??t login to  SIAE  NMS ...   \n",
       "4  Account Locked     Hi Team,        Can you please reset my U20...   \n",
       "\n",
       "   category_id                   New_Consumer_complaint_narrative  \n",
       "0            0  hi kindly unlock the mentioned ipcm account us...  \n",
       "1            0  good morning plese see the updte from the supp...  \n",
       "2            0  hi can you please assist with this am unable t...  \n",
       "3            0  hi eam can login o sae nm maser wed nm applica...  \n",
       "4            0  hi team can you please reset my password a am ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "def cleanup(message):\n",
    "    \n",
    "    # Remove all the numbers\n",
    "    document = re.sub(\"\\d+\", ' ', str(message))\n",
    "    \n",
    "    # Remove all the special characters\n",
    "    document = re.sub('[^A-Za-z0-9]+', ' ', document)\n",
    "    \n",
    "    # remove all single characters\n",
    "    for i in document.split():\n",
    "        if len(i) == 1:\n",
    "            document = document.replace(i , '')\n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "\n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "\n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "\n",
    "    return document\n",
    "\n",
    "\n",
    "def remove_signature(message):\n",
    "    string = \" \".join(str(message).split())\n",
    "\n",
    "    if 'Thank' in string:\n",
    "        return(cleanup(string.split('Thank')[0]))\n",
    "    elif 'thank' in string:\n",
    "        return(cleanup(string.split('thank')[0]))\n",
    "    elif 'Best Regard' in string:\n",
    "        return(cleanup(string.split('Best Regard')[0]))\n",
    "    elif 'Best regard' in string:\n",
    "        return(cleanup(string.split('Best regard')[0]))\n",
    "    elif 'Regard' in string:\n",
    "        return(cleanup(string.split('Regard')[0]))\n",
    "    elif 'regard' in string:\n",
    "        return(cleanup(string.split('regard')[0]))\n",
    "    elif 'BR' in string:\n",
    "        return(cleanup(string.split('BR')[0]))\n",
    "    else:\n",
    "        return(cleanup(message))\n",
    "    \n",
    "df['New_Consumer_complaint_narrative'] = df['Consumer_complaint_narrative'].apply(remove_signature)\n",
    "\n",
    "df.head()\n",
    "\n",
    "#df[['Product', 'New Consumer complaint narrative','Consumer complaint narrative']].to_csv(r'C:\\Users\\ezmanhi\\Desktop\\EGI-Emaildata\\test_email_complain.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Account Locked', 1: 'New Account', 2: 'Password Reset', 3: 'New account'}\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "import pickle\n",
    "category_id_df = df[['Product', 'category_id']].drop_duplicates().sort_values('category_id')\n",
    "category_to_id = dict(category_id_df.values)\n",
    "id_to_category = dict(category_id_df[['category_id', 'Product']].values)\n",
    "print(id_to_category)\n",
    "with open(\"category1.pkl\", 'wb') as file:\n",
    "    pickle.dump(id_to_category, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2),stop_words='english')\n",
    "features = tfidf.fit_transform(df.New_Consumer_complaint_narrative).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3407, 1069)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df.category_id\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'Account Locked':\n",
      "  . Most correlated unigrams:\n",
      "       . ount\n",
      "       . new\n",
      "       . locked\n",
      "  . Most correlated bigrams:\n",
      "       . prout deult\n",
      "       . new account\n",
      "       . account locked\n",
      "# 'New Account':\n",
      "  . Most correlated unigrams:\n",
      "       . account\n",
      "       . locked\n",
      "       . new\n",
      "  . Most correlated bigrams:\n",
      "       . reset password\n",
      "       . account locked\n",
      "       . new account\n",
      "# 'New account':\n",
      "  . Most correlated unigrams:\n",
      "       . requesting\n",
      "       . create\n",
      "       . dear\n",
      "  . Most correlated bigrams:\n",
      "       . account created\n",
      "       . create new\n",
      "       . dear team\n",
      "# 'Password Reset':\n",
      "  . Most correlated unigrams:\n",
      "       . password\n",
      "       . new\n",
      "       . account\n",
      "  . Most correlated bigrams:\n",
      "       . reset password\n",
      "       . account locked\n",
      "       . new account\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "\n",
    "N = 3\n",
    "for Product, category_id in sorted(category_to_id.items()):\n",
    "  features_chi2 = chi2(features, labels == category_id)\n",
    "  indices = np.argsort(features_chi2[0])\n",
    "  feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "  unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "  bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "  print(\"# '{}':\".format(Product))\n",
    "  print(\"  . Most correlated unigrams:\\n       . {}\".format('\\n       . '.join(unigrams[-N:])))\n",
    "  print(\"  . Most correlated bigrams:\\n       . {}\".format('\\n       . '.join(bigrams[-N:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['New_Consumer_complaint_narrative'], df['Product'], random_state = 0)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "model = LinearSVC()\n",
    "model = CalibratedClassifierCV(LinearSVC()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.55254485e-02 1.51428156e-02 9.47333267e-01 1.99846878e-03]\n",
      " [1.27907329e-01 8.32886814e-01 3.78359119e-02 1.36994441e-03]\n",
      " [1.76626446e-02 9.74994143e-01 5.37386792e-03 1.96934437e-03]\n",
      " ...\n",
      " [8.71517694e-02 1.09974202e-01 8.01051652e-01 1.82237622e-03]\n",
      " [1.76626446e-02 9.74994143e-01 5.37386792e-03 1.96934437e-03]\n",
      " [2.34217016e-02 7.17542970e-03 9.69092446e-01 3.10422792e-04]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(features, labels, df.index, test_size=0.33, random_state=0)\n",
    "model.fit(X_train, y_train,)\n",
    "y_pred = model.predict_proba(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "            cv='warn', method='sigmoid')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize weights to HDF5\n",
    "import pickle\n",
    "pickle.dump(model, open(\"model1.pkl\", 'wb'))\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tfidf model to disk\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(tfidf, open(\"tfidf1.pkl\", 'wb'))\n",
    "print(\"Saved tfidf model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9688888888888889\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(\"model1.pkl\", 'rb'))\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tfidf model from disk\n",
    "loaded_tfidf = pickle.load(open(\"tfidf1.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"Could you please renew my MBNL Citrix Password?\"]\n",
    "text_features = loaded_tfidf.transform(text)\n",
    "predictions = loaded_model.predict_proba(text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Account Locked', 1: 'New Account', 2: 'Password Reset', 3: 'New account'}\n",
      "Predicted as: Password Reset\n",
      "Confidence : 92.22556819295205%\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "indices = np.where(predictions == predictions.max())\n",
    "for predicted in predictions:\n",
    "    with open(\"category1.pkl\", 'rb') as file:\n",
    "        category = pickle.loads(file.read())\n",
    "        print(category)\n",
    "    print(\"Predicted as: %s\"%category[indices[1][0]])\n",
    "    print(\"Confidence : %s%%\"%(predictions.max()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enmuserauthkey\n"
     ]
    }
   ],
   "source": [
    "result =['Node   Auth Algo   Auth Password   Priv Algo   Priv Password' , 'MUN-ECAA042   SHA1    enmuserauthkey  DES enmuserprivkey']\n",
    "ret = ' '.join(result[1].split()).split(' ')[2]\n",
    "print (ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
