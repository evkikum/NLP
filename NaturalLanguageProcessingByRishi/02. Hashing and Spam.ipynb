{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing and Spam\n",
    "#### Article Classification(E.g: Spam Classification) using bag-of-words representation (BOW)\n",
    "\n",
    "Suppose we have two sentence one is span and other is not spam   \n",
    "- i earn 20 lakh rupees per month just chitchating on the net!(spam)  \n",
    "- are you free for a meeting anytime tomorrow?(not spam) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0]\n",
      " [1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1]]\n",
      "{'earn': 3, 'twenty': 16, 'lakh': 7, 'rupees': 13, 'per': 12, 'month': 9, 'just': 6, 'chitchating': 2, 'on': 11, 'the': 14, 'net': 10, 'are': 1, 'you': 17, 'free': 5, 'for': 4, 'meeting': 8, 'anytime': 0, 'tomorrow': 15}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "corpus = [\n",
    "     'i earn twenty lakh rupees per month just chitchating on the net!', \n",
    "     'are you free for a meeting anytime tomorrow?',\n",
    "]\n",
    "df = pd.DataFrame({'Text':corpus})\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_v = CountVectorizer()\n",
    "X = count_v.fit_transform(df.Text).toarray()\n",
    "print(X)\n",
    "print(count_v.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "#Now we got a new sentence, generate the vector using pre built vocabulary\n",
    "new_txt = ['io etrn are you free ruppee for a monnth meeting chitcchting anytime tomorrow neet']\n",
    "df_new = pd.DataFrame({'new_txt':new_txt})\n",
    "y = count_v.transform(df_new.new_txt).toarray()\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary:  \n",
    "{'anytime': 0, 'are': 1, 'chitchating': 2, 'earn': 3, 'for': 4, 'free': 5, 'just': 6, 'lakh': 7, 'meeting': 8,   'month': 9, 'net': 10, 'on': 11, 'per': 12, 'rupees': 13, 'the': 14, 'tomorrow': 15, 'twenty': 16, 'you': 17 }  \n",
    "  \n",
    "- i earn 20 lakh rupees per month just chitchating on the net!   \n",
    "vector1:[0 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0]  \n",
    "\n",
    "- are you free for a meeting anytime tomorrow?  \n",
    "vector2:[1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1]  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Sentence:  \n",
    "- io etrn are you free ruppee for a monnth meeting chitcchting anytime tomorrow neet  \n",
    "With Existing Count Vector:  \n",
    "vector3:[1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1]  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So, above vector3 is same as vector2, because new words can't be taken into account as this is CountVectorizer. So machine learning will classify vector3 as not spam same as vector2 which is not correct. \n",
    "- Even if we increase the vector length, whole machine learning model need to be trained again.  \n",
    "- Solution is Hashing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashing\n",
    "- Apply Hash Function\n",
    "- “Rishi Bansal”  --> 23\n",
    "- “Rashi Bansal” --> 72\n",
    "- Output number depend on Hash function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features:**\n",
    "- Same value for same string\n",
    "- Collison: Possibility of same value for different string \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a huge count vector – 2*2^20  \n",
    "Choose Hashing function which generates number between 0 to 2*2^20  \n",
    "'i earn 20 lakh rupees per month just chitchating on the net!',   \n",
    "[0 0 1 1…. 0 0 1 1 0….. 1 1 1 1 ……1 1 0 1 0]  – 2*2^20  \n",
    "\n",
    " 'are you free for a meeting anytime tomorrow?',  \n",
    "[1 1 …..0 0 1 1 0 0 ……1 0……. 0 0 0 0 …..0 1 0 1]  – 2*2^20  \n",
    "\n",
    " 'io etrn are you free ruppee for a monnth meeting chitcchting anytime tomorrow neet'  \n",
    "[00 …..1 0 1 1 0 0 ……1 0……. 1 0 1 0 …..0 0 0 1] – 2*2^20   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to Use HashVectorizer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HashingVectorizer : \n",
    "1> If dataset is large and there is no use for the resulting dictionary of tokens\n",
    "2> You have maxed out your computing resources and it’s time to optimize\n",
    "\n",
    "#### CountVectorizer: \n",
    "1>  If need is to access the actual tokens.\n",
    "2> If you are worried about hash collisions (when matrix size is small) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [3, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv(\"Data/emails.csv\")\n",
    "\n",
    "X = dataset[\"text\"]\n",
    "y = dataset[\"spam\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "spam_fil = CountVectorizer(stop_words=\"english\")\n",
    "#spam_fil.fit(X_train) \n",
    "#print(spam_fil.get_feature_names())\n",
    "\n",
    "X_train = spam_fil.fit_transform(X_train).toarray()\n",
    "X_test = spam_fil.transform(X_test).toarray()\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9022687609075044\n"
     ]
    }
   ],
   "source": [
    "#using K-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kneigh = KNeighborsClassifier(n_neighbors = 5)\n",
    "kneigh.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "pred_test = kneigh.predict(X_test)\n",
    "print(accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9505526468877254\n"
     ]
    }
   ],
   "source": [
    "#Using Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "pred_test_nb = nb_model.predict(X_test)\n",
    "print(accuracy_score(y_test, pred_test_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9936009307737056"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Naive Bayes Multinomial\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "mnb_model = MultinomialNB(alpha=1.8)\n",
    "mnb_model.fit(X_train.toarray(), y_train)\n",
    "pred_test_mnb = mnb_model.predict(X_test.toarray())\n",
    "accuracy_score(y_test, pred_test_mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
